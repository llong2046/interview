# 大模型面试高频核心要点（精炼版）

### 一、 基础核心概念

1.  **语言模型 (LM) & 自回归 (Autoregressive)**
    *   **语言模型**：一个预测词元（Token）序列概率分布的数学模型。
    *   **自回归**：一种生成模式，逐个预测下一个Token，且每一步都依赖于前面所有已生成的Token。这是GPT系列等生成式模型的基础。

2.  **Token & 模型规模 (7B, 13B)**
    *   **Token**: 模型处理语言的基本信息单元，可理解为“字”或“词”。
    *   **7B, 13B**: 指模型参数量的规模，B是Billion（十亿）的缩写。7B即70亿参数。参数量是衡量模型容量的关键指标。

3.  **基础模型 (Foundation Model) & 开源/闭源**
    *   **基础模型**: 在海量数据上通过自监督学习预训练的、可适配多种下游任务的大模型。
    *   **开源/闭源**: 指模型是否开放源代码和权重。开源（如LLaMA, ChatGLM）允许社区修改和研究；闭源（如GPT-4）通常只提供API访问。

4.  **涌现能力 (Emergent Abilities)**
    *   指当模型规模（参数、数据量）突破某个阈值后，突然获得了小模型不具备的、未被直接训练的新能力，如上下文学习、链式思考（CoT）推理等。

### 二、 核心架构与设计

1.  **三大核心架构**
    *   **Decoder-only**: 单向注意力（Causal LM），天然适合文本生成。**当前大语言模型的主流选择**。代表：GPT系列、LLaMA。
    *   **Encoder-only**: 双向注意力，强于理解完整上下文。代表：BERT。
    *   **Encoder-Decoder**: 编码器理解输入，解码器生成输出。代表：T5、BART。

2.  **为什么主流是 Decoder-only 架构？**
    *   **任务一致性**: 预训练（预测下一个词）和下游生成任务的目标一致，有利于发挥Zero-shot/Few-shot性能。
    *   **训练效率**: 结构简单，训练和推理可以高度并行化（KV Cache）。
    *   **RLHF 适配**: 更适合与RLHF（人类反馈强化学习）结合，因为RLHF依赖模型生成完整回复进行排序。

3.  **注意力机制 (Attention Mechanism)**
    *   **核心思想**: 允许模型在处理序列时，动态地为不同部分分配不同的“关注度”权重，从而捕捉长距离依赖关系。是Transformer架构的基石。

4.  **混合专家模型 (MoE - Mixture of Experts)**
    *   **目的**: 在不显著增加推理计算量的前提下，极大扩展模型参数规模。
    *   **原理**: 由多个“专家”子网络和一个“门控”网络组成。对于每个输入Token，门控网络会选择性地激活少数几个专家进行计算，而非全部。实现了“稀疏激活”，提升了训练和推理效率。

### 三、 模型训练与微调

1.  **ChatGPT 训练三步法**
    1.  **预训练 (Pre-training)**: 在互联网规模的无标签数据上进行自监督学习（预测下一个词），让模型掌握通用知识。
    2.  **监督微调 (SFT)**: 使用高质量的“指令-答案”数据对，有监督地微调模型，使其学会理解并遵循人类指令。
    3.  **人类反馈强化学习 (RLHF)**: 训练一个奖励模型（RM）来评估生成内容的优劣，然后用强化学习（PPO算法）根据奖励信号进一步微调模型，使其输出更符合人类偏好。

2.  **分布式训练**
    *   **目的**: 解决单机无法容纳巨大模型参数和数据的“内存墙”问题。
    *   **核心策略**: **数据并行**（模型复制，数据切分）、**模型并行**（模型切分，数据复制）、**流水线并行**（模型按层切分，接力计算）。实践中常将三者**混合使用**。

3.  **SFT 微调实践要点**
    *   **Base vs. Chat 模型**: `Base`模型是预训练完的基座，适合做通用任务的SFT；`Chat`模型是经过对话SFT和RLHF的，适合在对话基础上继续微调。
    *   **为什么SFT后模型“变傻”了？**: 核心是**灾难性遗忘**。因为微调数据分布与预训练数据差异大，导致模型遗忘了通用能力。也可能是数据质量差或过拟合。
    *   **如何缓解遗忘**: 在微调时，按一定比例**混入通用数据**进行训练；使用更小的学习率；冻结模型底层参数，只训练高层等。
    *   **显存计算**: 全参数微调所需显存约等于 **模型参数（FP32: 4*P）+ 优化器状态（AdamW: 8*P）+ 激活值**。1B模型约需12GB以上基础显存。

### 四、 模型应用与核心挑战

1.  **核心挑战 & 解决方案**
    *   **幻觉**: 通过**RAG (检索增强生成)** 引入外部知识，或通过高质量数据微调、强化学习来缓解。
    *   **重复生成**: 通过采样策略（Top-k, Top-p, Temperature）增加多样性，或引入重复惩罚（Repetition Penalty）。
    *   **长文本处理 (上下文扩展)**: 通过**外推技术**（如位置编码优化：RoPE, ALiBi）或**窗口化/分块处理**来处理超出训练长度的文本。

2.  **AI Agent (智能体)**
    *   **定义**: 一个具备自主感知、规划、执行、反思能力的智能实体，其“大脑”是LLM。
    *   **核心能力**: **规划**（任务拆解）、**工具调用**（Function Calling，与外部API交互）、**记忆**、**反思**（自我纠错）。

3.  **风险与危害**
    *   **社会偏见**: 模型会学习并放大训练数据中存在的性别、种族等偏见。
    *   **有害内容**: 可能生成不实信息、仇恨言论等。
    *   **安全与隐私**: 训练数据可能包含隐私信息，恶意使用可能导致安全风险。
