# 大模型基础知识面试核心要点

### 一、 核心概念 (Core Concepts)

*   **语言模型 (Language Model)**
    *   **定义**: 一个预测词元（Token）序列概率分布的数学模型。它的核心任务是判断一个句子“有多像人话”，并能基于已有内容生成下一个最可能的词。
    *   **核心思想**: 通过学习海量文本，掌握语法、语义和世界知识。例如，模型会认为 "猫吃老鼠" 的概率远高于 "老鼠吃猫"。

*   **基础模型 (Foundation Model)**
    *   **定义**: 在海量无标签数据上通过自监督学习预训练的大规模模型，是各种下游任务微调的“基座”。
    *   **特点**: 规模巨大（数十亿参数以上）、知识广博、具备通用性。
    *   **分类**: 分为**闭源模型**（如GPT-4，通过API访问）和**开源模型**（如LLaMA，代码权重公开）。

*   **涌现能力 (Emergent Abilities)**
    *   **定义**: 当模型规模（参数量、数据量）突破某个阈值后，突然表现出的、在小模型上不存在的复杂能力。
    *   **例子**: 上下文学习（In-Context Learning）、多步推理（Chain-of-Thought）、指令遵循等。这些能力并非被直接编程，而是在大规模训练中“涌现”出来的。

*   **Token**
    *   **定义**: 模型处理文本的基本单位，可以是一个词、一个字或一个子词（sub-word）。
    *   **作用**: 将自然语言文本分割成机器可以理解和处理的数值序列。

```
助记关键词: 概率分布, 基座模型, 规模效应, 基本单位
助记/类比:
语言模型: 像一个“懂王”，能判断一句话有多地道，还能接话。
基础模型: 一本内容极其丰富的“百科全书”，你可以基于它复印、划重点，制作成特定主题的“学习手册”。
涌现能力: 孩子长大后突然会写诗了，你没专门教，但他读书多了自己就“悟”了。
Token: 语言的“乐高积木”，模型用这些积木块来搭建和理解句子。
```

### 二、 模型架构与关键技术

*   **主流架构：Decoder-only**
    *   **定义**: 目前大模型（如GPT系列）最主流的架构，只使用Transformer的解码器部分。
    *   **优势**: 天然适合文本生成任务；训练目标简单统一（预测下一个词）；推理时可以通过KV-Cache高效加速。
    *   **对比**: **Encoder-only** (如BERT) 擅长理解，适合分类、填空任务；**Encoder-Decoder** (如T5) 适合序列到序列任务，如翻译。

*   **注意力机制 (Attention Mechanism)**
    *   **定义**: 允许模型在处理序列时，动态地为不同部分分配不同的“注意力权重”，从而聚焦于最相关的信息。
    *   **作用**: 解决了RNN难以处理长距离依赖的问题，是Transformer架构的核心。

*   **混合专家模型 (MoE - Mixture of Experts)**
    *   **定义**: 一种稀疏激活模型。它包含多个“专家”子网络和一个“门控”网络。
    *   **工作原理**: 门控网络根据输入动态选择激活一小部分专家来进行计算，而不是每次都动用整个模型的全部参数。
    *   **优势**: 在保持极大规模参数的同时，大幅降低了单次推理的计算量，实现了“用更大的模型，花更少的计算”。

```
助记关键词: 生成优先, 动态聚焦, 稀疏激活
助记/类比:
Decoder-only: 一个话痨小说家，永远在想下一句该写什么。
注意力机制: 你在嘈杂的派对上，能自动忽略背景噪音，只听清朋友对你说的话。
MoE: 一个大型咨询公司。接到一个金融问题，只激活金融专家组（一小部分人）来开会，而不是每次都让全公司（所有参数）几千人一起开会。
```

### 三、 训练与微调

*   **训练流程 (以ChatGPT为例)**
    1.  **预训练 (Pre-training)**: 在海量的互联网数据上进行无监督学习，让模型掌握通用知识和语言规律。
    2.  **监督微调 (SFT - Supervised Fine-tuning)**: 用高质量的“指令-答案”数据对模型进行微调，使其学会理解并遵循人类的指令。
    3.  **人类反馈强化学习 (RLHF)**: 训练一个奖励模型来评估生成答案的好坏，再用强化学习算法根据奖励信号进一步优化模型，使其输出更符合人类偏好。

*   **灾难性遗忘**
    *   **定义**: 在特定领域数据上微调后，模型在该领域表现提升，但其原有的通用知识和能力显著下降的现象。
    *   **缓解策略**: 
        1.  **混合训练**: 将领域数据和通用数据混合在一起进行训练。
        2.  **轻量化微调**: 使用LoRA等方法，只调整模型的一小部分参数，大部分参数保持不变。
        3.  **知识蒸馏**: 让微调后的模型（学生）模仿原始模型（老师）在通用问题上的输出。

*   **SFT后模型“变傻”**
    *   **现象**: 有时SFT后，模型虽然能很好地完成特定任务，但回答的通用性、创造性和逻辑性反而下降了。
    *   **原因**: 训练数据质量差、过于单一；过度拟合到特定格式；灾难性遗忘。

```
助记关键词: 三步走, 顾此失彼, 矫枉过正
助记/类比:
训练流程: 1. 读万卷书（预训练）；2. 学会怎么答题（SFT）；3. 学会怎么答题才能让老师满意（RLHF）。
灾难性遗忘: 一个全科医生去专修心脏科，结果把怎么看感冒给忘了。
SFT后变傻: 为了应试教育，把一个充满想象力的学生训练成了只会做选择题的机器。
```

### 四、 推理与优化

*   **长文本处理**
    *   **挑战**: 大多数模型有固定的上下文窗口长度限制（如4K, 8K）。
    *   **解决方案**: 
        1.  **滑动窗口**: 保持一个固定长度的窗口在长文本上滑动，但可能丢失全局信息。
        2.  **分块处理**: 将长文本切块，分别处理后再整合。
        3.  **位置编码外推**: 通过修改位置编码算法（如RoPE的NTK-aware Scaling），使其能处理超过训练长度的文本。

*   **重复问题**
    *   **现象**: 模型在生成文本时，有时会陷入循环，不断重复相同的词或句子。
    *   **缓解策略**: 
        1.  **重复惩罚 (Repetition Penalty)**: 在生成时降低已出现过的Token的概率。
        2.  **多样性采样**: 使用温度采样（Temperature）、Top-k或Top-p（Nucleus）采样，增加生成的随机性。

*   **分布式训练**
    *   **背景**: 模型参数量和数据量过大，单张GPU无法承载。
    *   **核心策略**:
        1.  **数据并行**: 不同GPU上放置完整的模型副本，但处理不同批次的数据，最后同步梯度。
        2.  **模型并行**: 将模型的不同部分（如不同的层）切分到不同的GPU上。
        3.  **流水线并行**: 模型并行的一种，将模型按层顺序切分，形成流水线作业。

```
助记关键词: 窗口扩展, 随机采样, 分而治之
助记/类比:
长文本处理: 读一本超长的小说，要么一目十行地扫读（滑动窗口），要么分章节阅读（分块）。
重复问题: 一个人说话卡壳了，为了让他别老说一个词，可以鼓励他“换个词说说”（多样性采样）。
分布式训练: 一项浩大的工程，要么是多个施工队（GPU）同时在不同的地块（数据）上建一样的房子（模型），这是数据并行；要么是把建房子的流程（模型）拆开，A队负责打地基，B队负责砌墙，这是模型/流水线并行。
```
